{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b72bc8e5",
      "metadata": {
        "id": "b72bc8e5"
      },
      "source": [
        "### Assignment-1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a1848d0",
      "metadata": {
        "id": "4a1848d0"
      },
      "source": [
        "### 1. How many unique values are there in categorical columns like `City`, `State`, and `Weather_Condition`? Which category is the most frequent in each?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('US_Accidents_March23.csv')  # Update path as needed\n",
        "\n",
        "# Columns to analyze\n",
        "columns = ['City', 'State', 'Weather_Condition']\n",
        "\n",
        "for col in columns:\n",
        "    print(f\"\\nColumn: {col}\")\n",
        "    print(\"Unique values:\", df[col].nunique())\n",
        "    print(\"Most frequent:\", df[col].value_counts().idxmax())\n",
        "    print(\"Count:\", df[col].value_counts().max())\n"
      ],
      "metadata": {
        "id": "a-s9EKQzQiCm"
      },
      "id": "a-s9EKQzQiCm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4e7ec556",
      "metadata": {
        "id": "4e7ec556"
      },
      "source": [
        "2. Calculate the percentage of missing values in each column and list columns with more than 5% missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceb88a2a",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "ceb88a2a"
      },
      "outputs": [],
      "source": [
        "# Calculate percentage of missing values for each column\n",
        "missing_percent = (df.isnull().mean() * 100).round(2)\n",
        "\n",
        "# Display all percentages\n",
        "print(\"Missing Value Percentage in Each Column:\\n\")\n",
        "print(missing_percent)\n",
        "\n",
        "# Columns with more than 5% missing data\n",
        "cols_over_5 = missing_percent[missing_percent > 5]\n",
        "\n",
        "print(\"\\nColumns with more than 5% missing data:\\n\")\n",
        "print(cols_over_5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dab9b53",
      "metadata": {
        "id": "7dab9b53"
      },
      "source": [
        "3. Convert `Start_Time` and `End_Time` columns to datetime objects. Find the range (earliest and latest) of accident start times in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "accb8a38",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "accb8a38"
      },
      "outputs": [],
      "source": [
        "# Convert to datetime\n",
        "df['Start_Time'] = pd.to_datetime(df['Start_Time'])\n",
        "df['End_Time'] = pd.to_datetime(df['End_Time'])\n",
        "\n",
        "# Find earliest and latest accident start times\n",
        "earliest = df['Start_Time'].min()\n",
        "latest = df['Start_Time'].max()\n",
        "\n",
        "print(\"Earliest accident start time:\", earliest)\n",
        "print(\"Latest accident start time:\", latest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16b841ec",
      "metadata": {
        "id": "16b841ec"
      },
      "source": [
        "4. Identify any duplicate records in the dataset based on all columns. How many duplicates exist and how will you handle them?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fde2c9b",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "6fde2c9b"
      },
      "outputs": [],
      "source": [
        "# Count duplicate records\n",
        "duplicates = df.duplicated().sum()\n",
        "print(\"Number of duplicate records:\", duplicates)\n",
        "\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e1b9654",
      "metadata": {
        "id": "0e1b9654"
      },
      "source": [
        "5. Explore the distribution of accident severity (Severity column). What percentage of accidents belong to each severity level? Visualize this distribution with a pie chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fc06851",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "0fc06851"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Percentage distribution of Severity\n",
        "severity_percent = (df['Severity'].value_counts(normalize=True) * 100).round(2)\n",
        "print(\"Percentage of accidents by severity level:\\n\")\n",
        "print(severity_percent)\n",
        "\n",
        "# Pie chart\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(\n",
        "    severity_percent,\n",
        "    labels=severity_percent.index,\n",
        "    autopct='%1.1f%%'\n",
        ")\n",
        "plt.title(\"Accident Severity Distribution\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}